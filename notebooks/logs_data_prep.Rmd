---
title: "las_reader"
output: html_document
---

```{r setup, include=FALSE}
source('../R/read_las_files.R')
library(tidyverse)
library(janitor)
library(data.table)
library(plot3D)
library(viridis)
library(raster)
library(sf)
# set study bounds
study_bound_coords <- rbind(
  c(460000, 5980000), c(460000, 6080000), c(560000, 6080000), 
  c(560000, 5980000), c(460000, 5980000)
  )

# make a polygon
study_bounds <- list(study_bound_coords) %>%
  st_polygon() %>%
  st_sfc(., crs = 26911) %>%
  st_sf(.)

study_proj = st_crs(study_bounds)$proj4string

# make a 2500x2500 m raster
study_raster <- raster(
  extent(study_bounds), 
  resolution = 2500,
  crs = st_crs(study_bounds)$proj4string
  )
```

# Load surface locations

We load the surface hole locations from the AGS well list layer, filter to make
sure they are in the study bounds, and combine them with the AGS well list to
get both the license, wellname, uwi etc.

```{r}
surface_locs = sf::st_read(
  dsn = '../data-raw/sh_shapefile/', layer='ST37_SH_GCS_NAD83') %>% 
  st_transform(., crs = 26911)

study_locs = surface_locs %>% filter(
  st_within(surface_locs, study_bounds,sparse = FALSE)
  ) %>% janitor::clean_names()

well_list = read_tsv(
  '../data-raw/sh_shapefile/WellList.txt', 
  col_names = c('uwi_disp','uwi','flag','name','field','pool','os_area',
                'os_dep','licence', 'status', 'issue_data', 'code','agent', 
                'operator','drill_data', 'td_m','stat_code', 'stat_date', 
                'fluid', 'mode', 'struct', 'scheme', 'scheme_sub')
  )

well_list$uwi_clean = well_list$uwi_disp %>% 
  str_c(1,.) %>%
  str_replace(., "/", "") %>% 
  str_replace(., "/", "0") %>% 
  str_replace_all(., "-", "")

# Merge with surface locations
study_locs = study_locs %>% 
  merge(well_list %>% dplyr::select(licence, uwi = uwi_clean), 
        on='licence', how='left')

st_write(study_locs, '../data/study_surf_locs.GeoJSON')
```

# Pull up las files

```{r}
files <- list.files('../data-raw/las_files/', full.names = FALSE)

file_uwis <- files %>%
    str_replace_all(., '.las', '') %>%
    str_replace_all(., 'w', 'W')

```

# Get unique study locations, and take mean surface location for point location

```{r}
unique_study_locs = study_locs %>% 
  filter((study_locs$uwi %in% file_uwis)) %>%
  dplyr::select(uwi, latitude, longitude, kbe, ground_elev, geometry) %>% 
  group_by(uwi) %>% 
  summarize_all(mean)

ggplot() +
  geom_sf(data=duvernay_iso) +
  geom_sf(data=unique_study_locs, aes(colour=ground_elev))


```
# Get Logs

Okay, so we have 108 logs in our study area. Not bad. Now we take those logs, 
subset using the AER 3D model

```{r}
study_files = files[file_uwis %in% unique_study_locs$uwi]
```

```{r}
get_log_data <- function(file){
  short_uwi <- file %>%
    str_replace(., '.las', '') %>%
    str_replace_all(., 'w', 'W')
  
  filename = str_c('../data-raw/las_files/',file)
  readLASFileIntoTable(filename, short = short_uwi)
}

log_list <- map(.x = study_files, get_log_data)

log_names <- map(.x = log_list, .f = colnames) %>%
  unlist() %>%
  unique()

logs_df <- bind_rows(log_list) %>%
  janitor::clean_names()

logs_df %>% fwrite(., '../data-raw/logs_df.csv')

log_summary = logs_df %>%
  group_by(uwi) %>%
  summarise(rows = n(), 
            rhob = sum(na.omit(rhob_qcgeo_k_m) > 0),
            dtc = sum(na.omit(dtc_qcgeo_us_m) > 0),
            dts = sum(na.omit(dts_qcgeo_us_m) > 0),
            gr = sum(na.omit(gr_qcgeo_gapi) > 0)
            )

log_summary %>% filter(gr>0)
# all logs have density (and thus vertical stress)
# 12/13 logs have compressional sonic
# 10/13 logs have shear sonic

write.csv(logs_df, 'duvernay_las_processed.csv')

logs_df <- read_csv('duvernay_las_processed.csv')
library(lasoo)
```
# Queue up the entire log set for the duvernay to see how many have dtc vs dts. 

```{r}
all_log_list <- map(.x = files[1], get_log_data)

write_rds(all_log_list, 'test_log_list.rds')

all_log_names <- map(.x = all_log_list, .f = colnames) %>%
  unlist() %>%
  unique()

all_logs_df <- bind_rows(all_log_list) %>%
  janitor::clean_names()

write_csv(all_logs_df, 'test_logs.csv')

all_logs_summary <- all_logs_df %>%
  group_by(uwi) %>%
  summarise(rows = n(), 
            rhob = sum(na.omit(rhob_qcgeo_k_m) > 0),
            dtc = sum(na.omit(dtc_qcgeo_us_m) > 0),
            dts = sum(na.omit(dts_qcgeo_us_m) > 0))



all_logs_df %>%
  group_by(uwi) %>%
  summarise(rows = n())
```

